# Design Patterns
> How should LLMs be used & applied?

>**Deductive Verification of Chain-of-Thought Reasoning ** \
[Paper](https://arxiv.org/abs/2306.03872) | Dataset | [Tweet](https://twitter.com/_akhaliq/status/1666252848781225987?s=20) | 6-Jun 2023 \
CoT: Intermediate steps can also hallucinations. So, apply logic checks.


>**ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning ** \
[Paper](https://arxiv.org/abs/2305.19426) | Dataset | [Tweet](https://twitter.com/ChrisGPotts/status/1666201393697558529?s=20) | 6-Jun 2023 \
Can LLMs handle negation. Easy, not!


>**ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory ** \
[Paper](https://arxiv.org/abs/2306.03901) | Dataset | [Tweet](https://twitter.com/omarsar0/status/1666254609524961282?s=20) | 6-Jun 2023 \
Have LLMs access symbolic memory for complex task planning and execution. 


>**Enabling Large Language Models to Generate Text with Citations ** \
[Paper](https://arxiv.org/abs/2305.14627) | Dataset | [Tweet](https://twitter.com/gaotianyu1350/status/1661186546907639808?s=20) | 5-Jun 2023 \
Asking an LLM to cite seems to be a way of reducing hallucinations, and also allows verification. 


>**LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion ** \
[Paper](https://arxiv.org/abs/2306.02561) | Dataset | [Tweet](https://twitter.com/_akhaliq/status/1665887472335695873?s=20) | 5-Jun 2023 \
Another co-op LLM idea.

>**ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing ** \
[Paper](https://arxiv.org/abs/2306.00622) | Dataset | [Tweet](https://twitter.com/jd92wang/status/1665596397788319744?s=20) | 5-Jun 2023 \
Use LLMs as reviewers:

>**Reimagining Retrieval Augmented Language Models for Answering Queries ** \
[Paper](https://arxiv.org/abs/2306.01061) | Dataset | [Tweet](https://twitter.com/_akhaliq/status/1665554751520485376?s=20) | 2-Jun 2023 \
Semi-parametric architectures can be enhanced with views, a query analyzer/planner, and provenance to make a significantly more powerful system for question answering in terms of accuracy and efficiency, and potentially for other NLP tasks

>**Decision-Oriented Dialogue for Human-AI Collaboration ** \
[Paper](https://arxiv.org/abs/2305.20076) | [Code](https://github.com/jlin816/dialop) | [Tweet](https://twitter.com/realJessyLin/status/1664410190719111168?s=20) | 2-Jun 2023 \
agents + humans collab to solve hard everyday problems


>**Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model ** \
[Paper](https://arxiv.org/abs/2305.17116) | Dataset | Blog | 2-May 2023 \
Applications of RAG (Retrieval Augmented Generation) and evaluation against GPT-4. It is a good pattern to apply!

>**SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL ** \
[Paper](https://arxiv.org/abs/2306.00739) | Dataset | Blog | 2-May 2023 \
A tailed model to inteact with DBs. Another important LLM pattern.


>**Letâ€™s Verify Step by Step ** \
[Paper](https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf) | [Dataset](https://github.com/openai/prm800k) | [Blog](https://openai.com/research/improving-mathematical-reasoning-with-process-supervision) | 31-May 2023 \
to solve math problems with CoT


>**Tree of Thoughts: Deliberate Problem Solving with Large Language Models **\
[Paper](https://arxiv.org/abs/2305.10601) | Code | Blog | May 2023 \
Generalzie CoT and solve harder problems

>**Interactive Natural Language Processing **\
[Paper](https://arxiv.org/abs/2305.13246) | Code | Blog | May 2023 \
LLMs as Agents. This seems to be a dominant  pattern. _This survey serves as an entry point for researchers who are interested in this rapidly evolving area and offers a broad view of the current landscape and future trajectory of iNLP_.


>**Reasoning with Language Model is Planning with World Model **\
[Paper](https://arxiv.org/abs/2305.14992) | Code | Blog | May 2023 \
LLMs as world models, reasoning & planning agents. 

>**How Does Generative Retrieval Scale to Millions of Passages? **\
[Paper](https://arxiv.org/abs/2305.11841) | Code | Blog | May 2023 \
An emerging pattern in LLMs is Retriveal Augmented Information Retrievel. Can Google search be made generative?

> **Small Models are Valuable Plug-ins for Large Language Models  **\
[Paper](https://arxiv.org/abs/2305.08848) | Code | Blog| May 2023 \
Use small models to provide the context. Big models will do better.

> **Crawling the Internal Knowledge-Base of Language Models  **\
[Paper](https://arxiv.org/abs/2301.12810) | Code | Blog| April 2023 \
Interesting. Thefore, treat LLMs as indexed web, and create structured data from unstructred web.

> **HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face **\
[Paper](https://arxiv.org/abs/2303.17580) | Code | Blog | Mar 2023 \
LLMs as controllers.


> **Collaborating with language models for embodied reasoning **\
[Paper](https://arxiv.org/abs/2302.00763) | Code | Blog | Feb 2023 \
A planner- actor- reporter: multiple LLMs work with each other.

> **Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents **\
[Paper](https://arxiv.org/abs/2302.01560) | Code | Blog | Feb 2023 \
Better error corrections by breaking the task into chunks!


> **Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing **\
[Paper](https://arxiv.org/abs/2107.13586) | Code | Blog | Jul 2021 \
The new way of solving NLP tasks: pre-train, prompt, and predict.
