# Sceptics
> too good to be true?


> **From Human-Centered to Social-Centered Artificial Intelligence: Assessing ChatGPT's Impact through Disruptive Events **\
[Paper](https://arxiv.org/abs/2306.00227) | Code | Blog | May 2023 \
Risk profiling LLMs in terms of hallucinations - rely on a Human-centered, individualistic evaluation framework. Do we need to a societal view as well? How doe proliferation of chatGPT like models affect societies?

> **The False Promise of Imitating Proprietary LLMs **\
[Paper](https://arxiv.org/abs/2305.15717) | Code | Blog | May 2023 \
Are the public models trained on imitated data (generated by bigger models like GPT) any good?
On indepedent datasets, the performance gaps are significant. Therefore, real data is the moat, not imitated/synthetic data!

> **Are Emergent Abilities of Large Language Models a Mirage? **\
[Paper](https://arxiv.org/abs/2304.15004) | Code | Blog | May 2023 \
Emergent abilities are researcher's choice of metrics, but not fundamental to LLMs. Need better evaluations.