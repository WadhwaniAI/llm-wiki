# Sceptics
> too good to be true?



> **The False Promise of Imitating Proprietary LLMs **\
[Paper](https://arxiv.org/abs/2305.15717) | Code | Blog | May 2023 \
Are the public models trained on imitated data (generated by bigger models like GPT) any good?
On indepedent datasets, the performance gaps are significant. Therefore, real data is the moat, not imitated/synthetic data!

> **Are Emergent Abilities of Large Language Models a Mirage? **\
[Paper](https://arxiv.org/abs/2304.15004) | Code | Blog | May 2023 \
Emergent abilities are researcher's choice of metrics, but not fundamental to LLMs. Need better evaluations.