# Methods
> Methods and Techniques


## PEFT

>**SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression ** \
[Paper](https://arxiv.org/abs/2306.03078) | Dataset | [Tweet](https://twitter.com/Tim_Dettmers/status/1666076553665744896?s=20) | 6-Jun 2023 \
LLMs can fit on your phones now.

> **LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model **\
[Paper](https://arxiv.org/abs/2304.15010) | [Code](https://github.com/ZrrSkywalker/LLaMA-Adapter/tree/main/imagebind_LLM) | [Tweet](https://twitter.com/lupantech/status/1664316926003396608?s=20)| Jun 2023 \
Via this Adaptor, LLM can perform open-ended multi-modal instructions by merely introducing 14M parameters over LLaMA. 

> **QLoRA: Efficient Finetuning of Quantized LLMs **\
[Paper](https://arxiv.org/abs/2305.14314) | [Code](https://github.com/artidoro/qlora) | Blog| May 2023 \
Quantize a pre-trained model, add an adapter and fine-tune via LoRA: a reciepe for creating new LLMs

> **Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes **\
[Paper](https://arxiv.org/abs/2305.02301) | Code | Blog| May 2023 \
Another type of PEFT (Performance Efficient Fine Tuning) like LoRA family, but train smaller models on narrow tasks, with smaller datasets.

> **SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot  **\
[Paper](https://arxiv.org/abs/2301.00774) | Code | Blog| Jan 2023 \
Without any retraining, prune large models under few hours

> **Cramming: Training a Language Model on a Single GPU in One Day **\
[Paper](https://arxiv.org/abs/2212.14034) | Code | Blog | Dec 2022 \
Cram It :)

## Build-TRain
>**Blockwise Parallel Transformer for Long Context Large Models ** \
[Paper](https://arxiv.org/abs/2305.19370) | Dataset | [Tweet](https://twitter.com/haoliuhl/status/1664396377252667393?s=20) | 2-Jun 2023 \
Train 7B models with over 130K or 13B models with over 64K context windows on just 8 A100 GPUs!


## RL
> **SLiC-HF: Sequence Likelihood Calibration with Human Feedback  **\
[Paper](https://arxiv.org/abs/2305.10425) | Code | Blog| May 2023 \
A simpler policy than PPO for use in RLHF, a key ingradient in GPT's success

## Prompting

> **Iterative Forward Tuning Boosts In-context Learning in Language Models  **\
[Paper](https://arxiv.org/abs/2305.13016) | [Code](https://github.com/artidoro/qlora) | Blog| May 2023 \
Another type of prompting? Like ICL, no-backprop but still adapt on examples!

> **Small Models are Valuable Plug-ins for Large Language Models  **\
[Paper](https://arxiv.org/abs/2305.08848) | Code | Blog| May 2023 \
Use small models to provide the context. Big models will do better.

## Thinkers

> **Multimodal Chain-of-Thought Reasoning in Language Models **\
[Paper](https://arxiv.org/abs/2302.00923) | Code | Blog | date \
Reason with multiple modlas in the chain of thoughts!

## Beyond Words

> **Unifying (Machine) Vision via Counterfactual World Modeling **\
[Paper](https://arxiv.org/abs/2306.01828) | Code | Blog | Jun 2023 \
LLMs can handle vision & speech

> **PolyVoice: Language Models for Speech to Speech Translation **\
[Paper](https://arxiv.org/abs/2306.02982) | Code | [Tweet](https://twitter.com/_akhaliq/status/1665927833095471105?s=20) | Jun 2023 \
LLMs can handle vision & speech

